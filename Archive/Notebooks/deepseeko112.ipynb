{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNUI64-VzA8o"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4kX30QAzMGP",
    "outputId": "f0b9bac9-ea73-4d55-c54e-f4bb59d466a5"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51xvyU7azVyp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "hf_token=userdata.get('deepseek011')\n",
    "\n",
    "#login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "u75Q3D3tzmCf",
    "outputId": "9f2a6d60-bb5a-4739-85f9-38b6e70c3afc"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wb_token = userdata.get(\"wandb\")\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on sft data',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "9ade413976bf4f7d921b90e8e197bb15",
      "a736bd5ca6f94726bd0710e1c86a288c",
      "88b636fed01f4fc5b2784b4fbe7b5d80",
      "a88125e1b74e46c39576a65480287447",
      "ae10719ecf5c41ed9cd165cd4636a05b",
      "c7d10d6719fa4d2e88e89847b120d23d",
      "a31cb1dcbac54198b135a287d07bf44a",
      "ba699d0126854ad3a37a7ab11133b3e9",
      "0a82b111cbe049f9b33ecab2b019e925",
      "dac87ba3bd3e40d1a5da887a253a986c",
      "c68e34613e0149b4ac892c40b6340708",
      "3d8e8efdb7cf450a9e199603d86dc90e",
      "fa590d5e65d747e58a70091a89a6a69d",
      "d2a94e2e82114af0b4870f0dac0b0955",
      "cae6aa80ae1d44c49362cf8c9e86d39d",
      "ff77ea78545e4190bab8a740eb610b6a",
      "57dfdc7f18af4f53a518f7318e20b039",
      "05f3b0f56d7247b2a8bc07f4b07d9e7a",
      "b6ec27343f63461dbe5d1c04e5a10249",
      "ed66f345e1ee4743b63640b036400cdb",
      "73347ab936d34f8d9872e300166a2cea",
      "5180e19c662f48968b3e542c5b5f83a9",
      "975baeeaba5740fbb4894021025088c9",
      "e56774c5fca844e2b9180184abc60b7d",
      "b412fa610d1148c38337cfaafcedbc49",
      "2bb9a6e2026845c08ec348c21f46f504",
      "8c4522f87be84b71a8704d468ce7cfff",
      "1cb457add13745f89f96cb4c47cecf51",
      "438101826f5b4a3e829a9d1f588795c6",
      "87bf9956474547749e546564cecaf6e4",
      "84e628a46c904015853f59ca791811d6",
      "9c80bb71a4dc4483b94d70e37f305fba",
      "70e192942b9e4bd2868f222c54a4587f",
      "828e88536f28434897da0f4f82bbc8c3",
      "10fa18a90277434e90aceefe0142199e",
      "7c46f0165d9d466497d77e656daa815a",
      "7638521c2aa348a19a78e7c5ace3525a",
      "0193093a4b104faeb79602a66b613eab",
      "bfa61b0848e242e68cb369642e81218b",
      "4a8ee41917004167bd82a8c4007364a9",
      "0b73d6bd65fb44e2ba00d821fd5f0ef5",
      "43fa7fa62a6140e1804c9d4867b7acaa",
      "1babd9025875469a8ff89c52ea81fd1a",
      "2d51aa67c12042f7b6a4af58013d5fff",
      "f724182a3faf4107908603ffd453ead8",
      "58924d771aad429ca963a91422a8d9da",
      "bf85a8d7e4584b4aaae23a5e99a41b0e",
      "627d89a0e852453bb653e6017a1bd79c",
      "a83ec78bd51d427a821e3175b7d54512",
      "6ffd722961a44cf88c8fdc4b9db3e0d1",
      "33b3f870a89346a2a2ebfcc3c4b84641",
      "87158e9c108d4732a6773d727aa878a5",
      "5628bc6c48bd4a5f92cc140839cfb2d9",
      "2ad1d42d41fa48b8902a7c1f41e85ad5",
      "72e035f77da042d288ccf01b75810271"
     ]
    },
    "id": "xZvj-qurzq8m",
    "outputId": "724978a3-1cec-4a77-90a0-d8432782b317"
   },
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMZUgVkmz4pA"
   },
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning and specialized on cancer diagostics.\n",
    "Please answer the following medical question.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uhq0wxsz9Bk",
    "outputId": "7dd4bfbb-84b8-498a-e7b7-52602e61546e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n",
    "\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iak9YxZG0EmW",
    "outputId": "8be9164b-b062-4be3-e216-1e9b49f0b3fe"
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Bwq-ggq0dn-"
   },
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
    "Please answer the following medical question.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tddt41xe0g6O"
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]\n",
    "    cots = examples[\"Complex_CoT\"]\n",
    "    outputs = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "10065b462d4b485384a8c88f7cb44658",
      "1a4a8c19da1846a5a5063c862ba0a096",
      "c7f4ba78021f45f29d49ef9fc59e5a1f",
      "f2cef2c1979a41db89981b84b728f5c5",
      "424505e0422840baa27b47d73760c65c",
      "05ac1aa943b3424e8b712da3a92bdefb",
      "1c6b8185d65346888e68f2cf50c14f71",
      "8a6a7f717b154200888f1f26e4d988bd",
      "3d49e0f4564e4d20bb550c18d40b4c54",
      "215b2c1190654bb9aa1ac10ef0539484",
      "4ea96cd5c8cb4640b9d28d93197aac8c",
      "858e134de4d1473e90d8e1f00804f14d",
      "3852ede6c5c54ed7b7c22a199c60a223",
      "5086b5c4de224839b0612474b29418ff",
      "2607a1d2d0614ee7a4a3a10c0e2cf7dd",
      "d396f74480b34649b067cdd997353992",
      "3e239f31abb3487281c13555ca8be92e",
      "9229e402c51b4552a821a1016de24f17",
      "85bd663fc7b74d8eab9556753defe6f4",
      "00fbdd0018d14b13aa15cc8b927ca145",
      "2ff45030fc29432db1d43c1ef01557b5",
      "cf88ff9758fa4ea1baa4d3b8313dd831",
      "2bac8776aaee449dad5e0e0c35971d2d",
      "d3187cc7ba0744948a6a728bd04d1e8d",
      "e7c2f0e20b8f4a3ea55e845a90a56186",
      "3612380fad9e4d55b821449ac80a289f",
      "c0eeefc75fdc4104b45215d4aef42b9d",
      "7f8b8267152e40aba42a2d2d43db9e0d",
      "00235445e2804b51a21178d40bbc8281",
      "3217491be4064961a5e5ef0609d8881e",
      "10ea7131d6634488906d8e8be949efa3",
      "72bf640d85e846b9b917c8bf589637eb",
      "ca3a770c6a8f4b039acdcb8ed241e0e4",
      "8d6981e64be946c3a16757e256b364ec",
      "cf829ec057fd4492b1b4e1d7a26735c6",
      "c940a38db1154d3ca40cb3127dea50de",
      "b328ab1136b14cf0b0c36900c19bad25",
      "179d005cdf0543bf92959089932e87c3",
      "134cf4fba82d493a987bf0c74173f7d1",
      "cf946ea0788749cf81d8a2fbde103e15",
      "ed853ac871bb40488a1441d18930d4eb",
      "cfcd7548e757459abbfb42a43a93ec55",
      "17f1452a19a547fba2597a53915b219b",
      "0d9e27f4e9f64c0788a2ca51c69bd652"
     ]
    },
    "id": "uOZlt2ao0jJu",
    "outputId": "28d95e88-8392-43ea-8406-6706d50ae3ab"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True)\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a75cf7c85144425ca69602baf3dbfdec",
      "24e54012f7d24c78b7955161ae382df9",
      "5e0c07b7a0994bceb0a8f65184372ffd",
      "b65b0e7d78d64f219122a5b4ed34b022",
      "8f836c0e0220493cb6119cdeb690fa84",
      "7b93c73601754ad7b1add88dccaaf2e1",
      "f6329fef258a45938dd5534a26d060f5",
      "a130292cda43472b8e27ed2ad517a598",
      "6575d111d8ca4d3a9669d633c7c4bd07",
      "cb5a5e348f2441c89b046d3ea21dfb8b",
      "72fc9e414b4449e5b1fc6bff85a4f39b"
     ]
    },
    "id": "bpQIfA7E0slY",
    "outputId": "1fbf2fff-8edc-49de-f64b-f246e9817606"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
    "        warmup_steps=5,\n",
    "        max_steps=60,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "VPbMmfYG0x17",
    "outputId": "5b8aa193-8eab-4352-e2da-537eb6a1731d"
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUUWhGUh00i5",
    "outputId": "aae8bb64-863a-4fa7-a61a-20b410bda77f"
   },
   "outputs": [],
   "source": [
    "question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n",
    "\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGJGLy2q03bw",
    "outputId": "2319a958-9428-4ecb-8a32-8dffd7f4be41"
   },
   "outputs": [],
   "source": [
    "question = \"What conditions might cause persistent fatigue, unexplained weight loss, a persistent cough, occasional fevers, and changes in bowel habits?\"\n",
    "\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### Response:\")[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
